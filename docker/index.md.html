<meta charset="utf-8">
                            **Elements of Docker Containers**
                            Stijn Heymans

# Introduction

Docker and containers in particular are presented as magic ("don't you dare
persisting anything in a container, it will be lost forever!"). As that's a
non-argument to start with (we all be lost forever!), I was interested in
figuring out some basics around containers. This article does not go terribly
deep. Staying elemental, I'll use the simplest of simple demo apps, I'll show
you how to _containerize_ it: build an image from it, publish the image, run
the image in a container. On that containerization road, I'll show you the
basic commands of manipulating container images, running containers, as well as
_volumes_ (_oh no, persistence, so difficult, don't even mention it_).

While writing these elements I mostly used [Docker Deep
Dive](https://www.goodreads.com/book/show/39933970-docker-deep-dive) by Nigel
Poulton as a reference which seems fairly complete to my layman eye but also
includes a lot of details that are not immediately relevant if you want to get
just the basics. 

You can download the demo code on
[github](https://github.com/sheymans/elementsOf/tree/master/docker/demo) and
follow along which is for this article probably the best approach for learning.
The demo is a Javascript app, but there's so little code it should not cause
too many side effects when consuming.

# The Demo App

There's nothing quite like a toy example that is absolutely nothing like you
will ever encounter in the real world, and I did my utter best to not
disappoint.  I'm going to use the simple web framework
[Express](expressjs.com) for [node](nodejs.org) to write an app that says `Hi`,
clearly a step down from "Hello World".

This is a simple `hi.js`:

~~~js
// Initialize your express app
const express = require('express');
const app = express();

// Tell your app that any GET should be resulting in a `Hi` returned to the user
app.get('/', (request, result) => result.send('Hi'));

// Your app will be listening on port 8111 and it 
// will announce this on the console when you start it
app.listen(8111, () => console.log('hi: listening on port 8111'));
~~~

As I'm using `express`, I'll have a `package.json`[^packagejson] file, that looks like this:

~~~
{
  "name": "hi",
  "version": "1.0.0",
  "author": "Stijn Heymans",
  "dependencies": {
    "express": "^4.17.1"
  }
}
~~~

Note that I indicated that my app will need `express` in this line:

~~~
    "express": "^4.17.1"
~~~

To make sure we can run this app, we'll install that `express` dependency as follows:

~~~bash
npm install
~~~

We use the node package manager [npm](https://www.npmjs.com/) to do that. `npm`
will look at the `package.json` file, will see that there's a `dependency`
`express` and will then install `express` into the directory `node_modules`.

To start your app, then type:

~~~bash
node hi.js
~~~

You can navigate to http://localhost:8111 to be said Hi to.

Here's roughly what assumptions we made to run this app on your laptop/computer:

- Your laptop allows for running software such as `npm` and `node`.  For example, it's a Linux or Mac Os X based machine.
- You had `npm` installed to install the required dependencies of your app (`express`); if you did not have it installed, you had to go and install it.
- You then ran `npm install` from the command-line
- You had `node` installed to actually run the application
- You then ran `node hi.js` from the command-line

If you want to install and run your app on another laptop (or, on an [EC2
instance](https://en.wikipedia.org/wiki/Amazon_Elastic_Compute_Cloud) cause
that's how you roll), you'd repeat those steps. 

_"Well, of course, I would not repeat these steps, I'd put them all in a little
script so I just have to run the script"_. Of course you would. But you'd be
forgetting that a laptop and an EC2 instance are very different things. You'd
probably want scripts per different Operation System at the minimumn.

What if you could package your app while specifying:

- a small Operating System to start from, for example [alpine](https://alpinelinux.org/)
- an installation of `npm` and `node` layered on that
- instructions to install your application (`npm install`)
- instructions to run your application (`node hi.js`)

In other words, what if you could define a small container that specifies the
above and that you run anywhere where such containers can run? (You're getting
the container reference: a standard packaging solution that you can stuff in
there and as long as your stuff fits into a container, you can put it on a ship
and ship it off anywhere in the world).

Next up, let's see how that containerization works.

# Containerizing the App

To containerize your app, we'll use [docker](docker.com). In this article, I'll
mostly focus on what `docker` _does_ rather than _how_ it does it. If you want
to learn more about how docker does what it does, please refer to [Docker Deep
Dive]() or for more on for example `containerd` and `runc`, check out this
[blog
series](https://www.ianlewis.org/en/container-runtimes-part-1-introduction-container-r).

Central to containerizing an app is the concept of an `image`. While there's a certain mysticism around an image, fundamentally it's just an abstraction that can be understood by `docker` when it needs to actually run your application. In that sense, we can compare to several other abstractions in computer science:

- a _Java class_ specifies the behavior of a particular instance of that class
- a _`jar` file_ packages up your Java application and can then be run by the Java runtime.
- an ISO image for Linux packages up the Operation System so you can download the image, install the image, and run the Operating System
- a Python script specifies which instructions to run for the Python interpreter

All of these comparisons are imperfect, but have in common that there is the
aspect of a specification (the `image`) that can then be run/executed on a
machine.

Let's recap the aspects that we'd like to specify for our demo app:

- a small Operating System to start from, for example [alpine](https://alpinelinux.org/)
- an installation of `npm` and `node` layered on that
- instructions to install your application (`npm install`)
- instructions to run your application (`node hi.js`)

Now let's write up that specification more formally (i.e., such that `docker`
can use to build an `image`) in a file named `Dockerfile` -- specifications to
build docker images will always be in a file named `Dockerfile` so similarly as
a `package.json` can teach you a lot of how the application is structured, have
a look at `Dockerfile`s in apps you meet in the wild.

We want our app to be layered on the Linux alpine OS system, so the first line of our `Dockerfile` is:


~~~
FROM alpine
~~~

Next, up we need an installation of `npm` and `node` layered over that, so let's specify that in the `Dockerfile`:

~~~
RUN apk add --update nodejs nodejs-npm
~~~

`apk add --update nodejs nodejs-npm` is just the command you'd run on alpine to
install `node` and `npm` (see
[apk](https://wiki.alpinelinux.org/wiki/Alpine_Linux_package_management). If
you picked a different image to start from, you'd might need a different
install command. The important part is `RUN` which runs whatever comes after it
and the installation of `node` and `npm` will constitute a new layer on top of
`alpine`.

Note that the directory where your `Dockerfile` exists is usually called the
_build-context_. We'll then copy all the files from this directory (in our
case, it will copy over `hi.js` and `package.json`) into a root directory
`/src` of the new image we're creating:

~~~
COPY . /src
~~~

The `.` is the current directory (i.e., where the `Dockerfile` lives). This
`COPY` command will create a new layer in the resulting image.

Alright, so we have an image consisting of a Linux (`alpine`), we've installed `node` and `npm` into that image and copied our app's source code into the directory `/src` on the image. Next up, let's use `npm` to install the `app`. For this, we'll make the `/src` directory our _current_ working directory and execute `npm install`:

~~~
WORKDIR /src
RUN npm install
~~~

`WORKDIR` changes the working directory to `/src` and you already know the
`RUN` command, it just executes `npm install` in this case. The latter will
just like it did on your laptop, look for `package.json`, find your
dependencies in there (`express`) and install those.

Almost there. Let's run our application:

~~~
ENTRYPOINT ["node", "./hi.js"]
~~~

This command sets the application to run when we `run` the container. Note that
we did not use `RUN` for this; `RUN` adds a new image layer, whereas
`ENTRYPOINT` just adds metadata and appears only once in the `Dockerfile` to
indicate _this is what you run once the container is ready to be run_.

We forgot one thing, which is that our app will be listening on port `8111`.
Our app would run entirely in the container so we'd not be able to access it
via `localhost` on our laptop unless we expose the container's port:

~~~
EXPOSE 8111
~~~

To round it of, we add some more metadata to the image:

~~~
LABEL maintainer="ben@ny.com"
~~~

This is the whole `Dockerfile`:

~~~
FROM alpine
RUN apk add --update nodejs nodejs-npm
COPY . /src
WORKDIR /src
RUN npm install
ENTRYPOINT ["node", "./hi.js"]
EXPOSE 8111
LABEL maintainer="ben@ny.com"
~~~

Let's build an image:

~~~
 docker image build -t hi:latest .
~~~

Dissected:

- `docker`: the `docker` program that we use to build images, run images, etc
- `image`: tell `docker` that we're doing involves images (you'd also have `docker container` to indicate that you're working with containers)
- `build`: build an image
- `-t hi:latest`: we're *t*argetting an image with name `hi` and with tag `latest`. A tag can be used to identified different versions of your software (`v1`, etc).
- `.`: don't forget the `.`. The `.` stands for _look into your current directory for the Dockerfile_. 

Let's have a look at whether we now indeed have an image available:

~~~
docker image ls
~~~

Dissecting that again:

- `docker`: the `docker` program (no, really?)
- `image`: we're dealing with images (what's the images around?)
- `ls`: the usual listing command

This should give as output something like:

~~~
REPOSITORY                                                                     TAG                             IMAGE ID            CREATED             SIZE
hi                                                                             latest                          5d3095b79194        5 minutes ago       57.2MB
~~~

So we're seeing a created image with repository name `hi`, tag `latest`, and
image id `5d3095b79194` (this will be different when you do it). 

Often it's nice to be able to just get the `IMAGE ID`s (for example to pipe them to another command), you can use `--format` for that which uses [Go templates](https://golang.org/pkg/text/template/) to extract the data you like to see formatted. For example, let's say we want to see the size:

~~~
docker image ls --format "{{.Size}}"
~~~

This will show:

~~~
57.2MB
~~~

More useful is often getting the Image Ids, so you try:

~~~
docker image ls --format "{{.ImageId}}"
~~~

and you get:

~~~
Template parsing error: template: :1:2: executing "" at <.ImageId>: can't evaluate field ImageId in type formatter.imageContext
~~~

So while `docker image ls` shows `IMAGE ID` as a column name, that's not how you can access this. There's a nice [hint](https://docs.docker.com/config/formatting/) on how you can see the attributes that you can actually use in `--format`:

~~~
docker image ls --format "{{json .}}"
~~~

This will make a json out of _everything_ and will show:

~~~
{"Containers":"N/A","CreatedAt":"2020-03-25 08:11:44 -0700 PDT","CreatedSince":"2 days ago","Digest":"\u003cnone\u003e","ID":"5d3095b79194","Repository":"hi","SharedSize":"N/A","Size":"57.2MB","Tag":"latest","UniqueSize":"N/A","VirtualSize":"57.23MB"}
~~~

From which you can see that the `IMAGE ID` is actually under attribute `ID`:

~~~
docker image ls --format "{{.ID}}"
~~~

will give you `5d3095b79194`.

Finally, let's have a look at our created image:

~~~
docker image inspect 5d3095b79194
~~~

You'll see your label `maintainer` added, you'll see the entrypoint `node
./hi.js`, and you'll see the different layers with different ids that were
created as part of this image (recall that each `RUN` created a different
layer). Grab a cup of coffee and spend some time quality time with that `docker
image inspect` output, cause you're worth it.

# Publishing the Container

In this elemental example, we'll keep working with the local image we just
created. However, if you want other users to be able to use your image, you'd
upload it, for example to the [Docker Hub](https://hub.docker.com/). After you
uploaded your image to a Docker Hub repository, other developers could then
pull it down. Have a look at this
[tutorial](https://ropenscilabs.github.io/r-docker-tutorial/04-Dockerhub.html)
if you'd like to see some of the steps involved.

# Running the Container

Now that we have an image `hi:latest`, let's try to create a running instance
of that image. Where before we used `docker image` to do image manipulation,
we'll now use `docker container` indicating that we're running containers based
off an image:

~~~
docker container run -d hi:latest
~~~

This basic command starts the container in detached/background mode (hence the
`-d`) and uses the image `hi:latest` to instantiate the container with. Since
we specified that this container should be running `node ./hi.js` using its
`ENTRYPOINT` statement in the `Dockerfile`, we expect to see this app running
when we _jump into_ the container.

Let's first check what the ID or name of this freshly started container is:

~~~
docker container ls
~~~

We'd see something like this as output:

~~~
CONTAINER ID        IMAGE                COMMAND                  CREATED             STATUS              PORTS                    NAMES
885288159d28        hi:latest            "node ./hi.js"           2 minutes ago       Up 2 minutes        8111/tcp                 boring_dijkstra
~~~

You'll see that a name was created for your running container
`boring_dijkstra`. We could have decided on that name ourselves by using
`docker container run --name your_own_name -d hi:latest`.

We see from that `docker container ls` that there's a container running with id
`885288159d28` and it's executing the command `node ./hi.js` which is exactly
what we expected from the `Dockerfile`.

We can quickly jump into the container to see that in action:

~~~
docker container exec -it boring_dijkstra sh
~~~

Note that I used the name of the container `boring_dijkstra`, but I could as well have used its ID `885288159d28`.

You'll see a shell prompt appear and if you see what processes are running in this container, you'll indeed see our `node` app:

~~~
/src # ps
PID   USER     TIME  COMMAND
  1   root     0:00  node ./hi.js
 32   root     0:00  sh
 37   root     0:00  ps
~~~

You'll also see `sh` which is the command we executed as part of `docker container
exec -it boring_dijkstra sh` and of course `ps` which is the command we just
ran in that shell.

Let's analyze `docker container exec -it boring_dijkstra sh` in detail:

- `docker container`: you're executing docker and it involves containers (in contrast to `image` or `volume` see later)
- `exec`: you're going to execute a command in the container, which command? `sh`.
- `boring_dijkstra`: the container you're executing the command `sh` in
- `-it`: `-t` is short for `--tty` and attaches you to a terminal in the container. `-i` is to make input and output from the container flow to your terminal on your docker host (your laptop). You almost always see `-it` being used together: try out `-t` on its own in the previous command press `return`; you'll see nothing happen as the output of the container is not flowing to the output of your laptop terminal. I find it most useful to thin of `-it` as `interactive mode` and `-d` as detached mode (the container runs but you're not _in it_).
- `sh`: the command you're executing on your container.

The page explaining
[exec](https://docs.docker.com/engine/reference/commandline/exec/) as well as
this [stackoverflow
article](https://stackoverflow.com/questions/22272401/what-does-it-mean-to-attach-a-tty-std-in-out-to-dockers-or-lxc)
have more details that are worth skimming through.


So we know our app is running in the container. We also know that we wrote it so it runs on port `8111`. Indeed in `hi.js`:

~~~
app.listen(8111, () => console.log('hi: listening on port 8111'));
~~~

In the `Dockerfile` we also exposed that port:

~~~
EXPOSE 8111
~~~

In contrast to what you'd think this does not actually make the port `8111`
_reachable_; you can see this more as documentation that your service listens
to this port (`8111`).

To actually make your port `8111` from your container reachable from outside your container from your laptop, you'd publish it with the `-p` option.

Before using that `-p` option, let's first `stop` and `rm` our currenty running container:

~~~
docker container stop boring_dijkstra
docker container rm boring_dijkstra
~~~

And let's now start a container from the `hi:latest` image where we map the
Docker host's port `8000` (if you're following along this is most likely your
laptop) to the `8111`. For reading-left-to-right oriented cultures, this is
roughly from outward to inward (left to right).

~~~
docker container run -d -p 8000:8111 hi:latest
~~~

After this you can navigate to `localhost:8000` on your browser and see `Hi`.
Note that `localhost:8111` as `8111` is exposed in your container, not your
`localhost` (laptop).

Before diving into persistence, let's dive shortly into these `stop` and `rm`
commands we executed before starting a new container.

What's the difference? If you remove (`rm`) a container, you'll no longer be
able to start it again, you'll no longer be able to refer to it using its name,
and `docker container ls -a` (show all containers) will no longer show your
container. It's a goner. Anything your application wrote (for example, to
`/tmp`, any logs, anything) will be gone.

If you `stop` a container, you merely, suspend it. After having stopped it, you
can restart it with `docker container start your_container_name`. After
starting it again, whatever you wrote to `/tmp` for example is still there
after starting it again. While your container is stopped your app will not be
running, for example, if you stop your container with `docker container stop
your_container_name`, you'll no longer be able to navigate to `localhost:8000`.
Restarting the container on the other hand, brings `localhost:8000` back to
life.

# Persistence

When you mention _persistence_ in the context of docker or kubernetes, people
get upset: _you can't do that, don't do that, omg you so stoopid_. I am of
course not paraphrasing. People get upset. 

Of course you can persist stuff from a container. What do I mean with persist?
A typical example would be logs. Of course you can write logs and not lose them
after the container is removed. There are other types of persistence like
writing to a database table (and yes, of course, your data and table would
still exist outside of your container, presuming that it lives _outside_ your
container, or in other words, has a lifecycle that is independent of your
container). Your dog is also not going to die when your container dies, they're
lifes are not tied together. 

_But I'm talking about writing to the file-system man!! you're not
listening!!_. That's my default, yes, to not listen.

The _magic_ that allows docker to write to _the_ (a?) file-system that persist
after the container is long gone and forgotten is by using _volumes_.

Before diving into volumes, let's step back one step and talk about the type of
persistence we already have without speaking volumes. I can have my app that
runs in a container write to `/tmp` without issues while the container is
running. I can even `stop` the container (suspending it, as we saw above) and
when I come back to this container, the data I wrote to `/tmp` would still be
there. It's only when I `rm` the container that data in `/tmp` would be gone as
`rm` is literally wiping away the file-system of the container.

So that's already less drama that you were hoping for. Let's disappoint you even more.
The key to volumes is that they live and die outside of your container's life
cycle. They're an abstraction of storage: I can write to a volume, I can read
from a volume, so my logs, yes, they can go there. So if I have these 2
independent entities: a volume that I can write to/read from and a container
that potentially could be doing that writing and reading, how do I connect
those? Well, you mount the volume to a directory on your container. So so your
container has a directory `/logs`, you can then mount your volume to the
directory `/logs`. After that mounting, anything written to the `/logs` will be
written to mounted volume, everything read from `/logs` will actually be read
from the mounted volume.

Let's create a volume:

~~~
docker volume create dramatic_vol
~~~

Similar to the above, where we had `docker image` for image manipulation,
`docker container` for container manipulation, we have `docker volume` for
volume manipulation. Check whether it's there:

~~~
docker volume ls
~~~

Let's now attach `dramatic_vol` to a container running based on the image `hi:latest`:

~~~
docker container run -d --mount target=/src, source=dramatic_vol hi:latest
~~~

Let's find out the name of that container:

~~~
$ docker container ls
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
0abd6c82cee2        hi:latest           "node ./hi.js"      54 seconds ago      Up 52 seconds       8111/tcp            laughing_pike
~~~

And let's then check out the container `laughing_pike`:

~~~
docker container inspect laughing_pike
~~~

You'll see lots of output, among which this snippet:

~~~
 "Mounts": [
            {
                "Type": "volume",
                "Name": "dramatic_vol",
                "Source": "/var/lib/docker/volumes/dramatic_vol/_data",
                "Destination": "/src",
                "Driver": "local",
                "Mode": "z",
                "RW": true,
                "Propagation": ""
            }
        ],
~~~

So there you go: our volume `dramatic_vol` is part of the mounts, it indicates
where the data for that volume actually lives on my laptop
(`/var/lib/docker/volumes/dramatic_vol/_data`) and it indicates to what
directory _in the container_ it was  tied: `/src`.  Recall that anything
written to `/src` by my app in the container would be written to the volume
(and you could check that out at `/var/lib/docker/volumes/dramatic_vol/_data`).

If you `stop` and `rm` the container, none of the data on the volume would be
affected. It'd be persistent.

# Conclusion

I showed you how to build an image out of your app, how to run a container
based on that image, and how to persist the data that you write in the
container beyond the life cycle of that container using volumes. There's a lot
I didn't talk about as I think this is enough to give you the basics to delve
further and to sound like you know what the hell is going on with all that
container-talk (we both know you only scratch the surface, but my hope is tha
you scratch it a tiny bit more than the dev sitting next to you and that you
now have the elements to dig deeper. Things I know I left out: discussions on tags, docker
swarm, docker networking, `docker-compose`. Things I don't know I left out: $\infty$.

# Footnotes

[^packagejson] A `package.json` is used to describe your application (the
metadata for your example) so that `npm` (which can be used to build your
application) knows _how_ to build it. You can read some more about it
[here](https://nodejs.org/en/knowledge/getting-started/npm/what-is-the-file-package-json/).

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-12447521-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];

  function gtag() {
    dataLayer.push(arguments);
  }

  gtag('js', new Date());

  gtag('config', 'UA-12447521-1');
</script>

<link rel="stylesheet" href="https://casual-effects.com/markdeep/latest/latex.css?">
<!-- Markdeep: --><style class="fallback">body{visibility:hidden}</style><script src="https://casual-effects.com/markdeep/latest/markdeep.min.js?" charset="utf-8"></script>

